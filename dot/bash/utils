#!/bin/bash

gr() { grep -r "$@" .; }

# This will show a list of all unique extensions found on all files
# resulting from the `ls` along with their frequencies.
lsext() {
    # Use unaliased version of ls.
    command ls "$@" | sed -n 's/.*\(\.[^./].*\)$/\1/p' \
                    | sort                             \
                    | uniq -c                          \
                    | sort -nr
}

# Abbreviate a path if it is  too long by reducing each component
# to only the first letter.
abbr_path() {
    local max="$1"; local result="$2"

    # If the path is not considered too long then don't  condense
    # it at all.
    (( ${#result} < max )) && {
        echo "$result"
        return 0
    }

    # Keep repeating while we find sequences of two or  more  non
    # forward-slash characters. Each time  we  find one, the last
    # character of it will be  removed,  so  it may take multiple
    # iterations  just  to abbreviate a single path component. If
    # we could somehow make the initial (.*) not greedy then this
    # would take fewer iterations of the loop.
    while [[ "$result" =~ (.*)([^/])[^/]+(.*) ]]; do
        local part1="${BASH_REMATCH[1]}"
        local part2="${BASH_REMATCH[2]}"
        local part3="${BASH_REMATCH[3]}"
        result="$part1$part2$part3"
    done

    # This is how we return the result.
    echo "$result"
}

# This is the one we will call from inside of the PS1 variable.
ps1_path() {
    local max="$1"; local path="$2"

    # Use  value  in  COLUMNS  env variable if it is set. Ideally
    # here we'd like to get  the  length  of  the PS1 prefix (non
    # path component) and then subtract  that,  but it is kind of
    # hard to do that without evaluating PS1 and  going  into  an
    # infinite  loop  (since  evaluation  of the PS1 variable may
    # call this function).
    (( COLUMNS > 0 )) && max=$(( COLUMNS - 38 ))

    abbr_path "$max" "$path"
}

# Given a URL to an SVN repository this will  find  the  revision
# and folder from which it was copied. Doesn't really make  sense
# to  run  this on trunk, and doing so would probably hang anyway,
# so it checks for that and aborts if necessary.
svn_copied_from() {
    local what="$1"
    [[ "$what" =~ .*trunk.* ]] && {
        echo 'should not run this on trunk' >&2
        return 1
    }
    local svn_log="svn log -l1 -r1:HEAD --stop-on-copy --verbose"
    local rev=$($svn_log "$what" | grep '(from ')
    regex='.* \(from /([^:]+):([0-9]+)\)$'
    [[ "$rev" =~ $regex ]] || {
        echo 'failed' >&2
        return 1
    }
    echo "folder: ${BASH_REMATCH[1]}"
    echo "rev:    ${BASH_REMATCH[2]}"
}

# Quickly find a file given a fragment of the name.
f() {
    if [[ "$1" =~ \* || "$1" =~ \? ]]; then
        find . -name "*$1*"
    else
        find . -name "*$1*" | grep "$1"
    fi
}

# Remove from working copy
exclude()   { svn update --set-depth=exclude "$@"; }
exclude_r() { exclude "$@" && rm -rf "$@";         }

# df -h -P command sorted on given column.
__dfs() {
    local sort_by=$1
    local cmd='df -h -P'
    # First print column headers
    $cmd | head -n1
    $cmd | tail -n +2 | sort -k${sort_by}hr
}

# df -h -P command sorted by total storage.
dfst() { __dfs 2; }
